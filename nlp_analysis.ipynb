{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import PunktSentenceTokenizer \n",
    "text =  \"best, good, better, nice, connectivity, connection, connecting I just wanted to find some really cool new places such as Seattle in November. I’ve never visited before but no luck here. Some of these suggestions are just terrible... I had to laugh! Most suggestions were just your typical big cities, restaurants and bars. Nothing off the beaten path here. I don’t want to go these places for fun. Totally not worth getting this, This was such a beautiful book. I wasn’t even planning any travel when I came across this and just started flipping through the pages. I really like the cover and all the large glossy photographs in this book. John Smith did a wonderful job with the photography. I’ve found a perfect home for this on my coffee table. I’m planning a trip to Paris and Barcelona soon and I know this will come in handy. In the meantime, it’s perfect for assisting this armchair traveler, As a traveler, I really appreciated reading about these great places to visit. The author takes you all over the world. Even with all the free information online these days, I find I’m taking this book with me wherever I go and using it to discover hidden gem, this product was not good, i love this product, this product was not as expected, i like this product was nice to use\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best, good, better, nice, connectivity, connection, connecting I just wanted to find some really cool new places such as Seattle in November.',\n",
       " 'I’ve never visited before but no luck here.',\n",
       " 'Some of these suggestions are just terrible... I had to laugh!',\n",
       " 'Most suggestions were just your typical big cities, restaurants and bars.',\n",
       " 'Nothing off the beaten path here.',\n",
       " 'I don’t want to go these places for fun.',\n",
       " 'Totally not worth getting this, This was such a beautiful book.',\n",
       " 'I wasn’t even planning any travel when I came across this and just started flipping through the pages.',\n",
       " 'I really like the cover and all the large glossy photographs in this book.',\n",
       " 'John Smith did a wonderful job with the photography.',\n",
       " 'I’ve found a perfect home for this on my coffee table.',\n",
       " 'I’m planning a trip to Paris and Barcelona soon and I know this will come in handy.',\n",
       " 'In the meantime, it’s perfect for assisting this armchair traveler, As a traveler, I really appreciated reading about these great places to visit.',\n",
       " 'The author takes you all over the world.',\n",
       " 'Even with all the free information online these days, I find I’m taking this book with me wherever I go and using it to discover hidden gem, this product was not good, i love this product, this product was not as expected, i like this product was nice to use']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = PunktSentenceTokenizer()\n",
    "sentences = tokenizer.tokenize(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best',\n",
       " ',',\n",
       " 'good',\n",
       " ',',\n",
       " 'better',\n",
       " ',',\n",
       " 'nice',\n",
       " ',',\n",
       " 'connectivity',\n",
       " ',',\n",
       " 'connection',\n",
       " ',',\n",
       " 'connecting',\n",
       " 'I',\n",
       " 'just',\n",
       " 'wanted',\n",
       " 'to',\n",
       " 'find',\n",
       " 'some',\n",
       " 'really',\n",
       " 'cool',\n",
       " 'new',\n",
       " 'places',\n",
       " 'such',\n",
       " 'as',\n",
       " 'Seattle',\n",
       " 'in',\n",
       " 'November',\n",
       " '.',\n",
       " 'I',\n",
       " '’',\n",
       " 've',\n",
       " 'never',\n",
       " 'visited',\n",
       " 'before',\n",
       " 'but',\n",
       " 'no',\n",
       " 'luck',\n",
       " 'here',\n",
       " '.',\n",
       " 'Some',\n",
       " 'of',\n",
       " 'these',\n",
       " 'suggestions',\n",
       " 'are',\n",
       " 'just',\n",
       " 'terrible',\n",
       " '...',\n",
       " 'I',\n",
       " 'had',\n",
       " 'to',\n",
       " 'laugh',\n",
       " '!',\n",
       " 'Most',\n",
       " 'suggestions',\n",
       " 'were',\n",
       " 'just',\n",
       " 'your',\n",
       " 'typical',\n",
       " 'big',\n",
       " 'cities',\n",
       " ',',\n",
       " 'restaurants',\n",
       " 'and',\n",
       " 'bars',\n",
       " '.',\n",
       " 'Nothing',\n",
       " 'off',\n",
       " 'the',\n",
       " 'beaten',\n",
       " 'path',\n",
       " 'here',\n",
       " '.',\n",
       " 'I',\n",
       " 'don',\n",
       " '’',\n",
       " 't',\n",
       " 'want',\n",
       " 'to',\n",
       " 'go',\n",
       " 'these',\n",
       " 'places',\n",
       " 'for',\n",
       " 'fun',\n",
       " '.',\n",
       " 'Totally',\n",
       " 'not',\n",
       " 'worth',\n",
       " 'getting',\n",
       " 'this',\n",
       " ',',\n",
       " 'This',\n",
       " 'was',\n",
       " 'such',\n",
       " 'a',\n",
       " 'beautiful',\n",
       " 'book',\n",
       " '.',\n",
       " 'I',\n",
       " 'wasn',\n",
       " '’',\n",
       " 't',\n",
       " 'even',\n",
       " 'planning',\n",
       " 'any',\n",
       " 'travel',\n",
       " 'when',\n",
       " 'I',\n",
       " 'came',\n",
       " 'across',\n",
       " 'this',\n",
       " 'and',\n",
       " 'just',\n",
       " 'started',\n",
       " 'flipping',\n",
       " 'through',\n",
       " 'the',\n",
       " 'pages',\n",
       " '.',\n",
       " 'I',\n",
       " 'really',\n",
       " 'like',\n",
       " 'the',\n",
       " 'cover',\n",
       " 'and',\n",
       " 'all',\n",
       " 'the',\n",
       " 'large',\n",
       " 'glossy',\n",
       " 'photographs',\n",
       " 'in',\n",
       " 'this',\n",
       " 'book',\n",
       " '.',\n",
       " 'John',\n",
       " 'Smith',\n",
       " 'did',\n",
       " 'a',\n",
       " 'wonderful',\n",
       " 'job',\n",
       " 'with',\n",
       " 'the',\n",
       " 'photography',\n",
       " '.',\n",
       " 'I',\n",
       " '’',\n",
       " 've',\n",
       " 'found',\n",
       " 'a',\n",
       " 'perfect',\n",
       " 'home',\n",
       " 'for',\n",
       " 'this',\n",
       " 'on',\n",
       " 'my',\n",
       " 'coffee',\n",
       " 'table',\n",
       " '.',\n",
       " 'I',\n",
       " '’',\n",
       " 'm',\n",
       " 'planning',\n",
       " 'a',\n",
       " 'trip',\n",
       " 'to',\n",
       " 'Paris',\n",
       " 'and',\n",
       " 'Barcelona',\n",
       " 'soon',\n",
       " 'and',\n",
       " 'I',\n",
       " 'know',\n",
       " 'this',\n",
       " 'will',\n",
       " 'come',\n",
       " 'in',\n",
       " 'handy',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'meantime',\n",
       " ',',\n",
       " 'it',\n",
       " '’',\n",
       " 's',\n",
       " 'perfect',\n",
       " 'for',\n",
       " 'assisting',\n",
       " 'this',\n",
       " 'armchair',\n",
       " 'traveler',\n",
       " ',',\n",
       " 'As',\n",
       " 'a',\n",
       " 'traveler',\n",
       " ',',\n",
       " 'I',\n",
       " 'really',\n",
       " 'appreciated',\n",
       " 'reading',\n",
       " 'about',\n",
       " 'these',\n",
       " 'great',\n",
       " 'places',\n",
       " 'to',\n",
       " 'visit',\n",
       " '.',\n",
       " 'The',\n",
       " 'author',\n",
       " 'takes',\n",
       " 'you',\n",
       " 'all',\n",
       " 'over',\n",
       " 'the',\n",
       " 'world',\n",
       " '.',\n",
       " 'Even',\n",
       " 'with',\n",
       " 'all',\n",
       " 'the',\n",
       " 'free',\n",
       " 'information',\n",
       " 'online',\n",
       " 'these',\n",
       " 'days',\n",
       " ',',\n",
       " 'I',\n",
       " 'find',\n",
       " 'I',\n",
       " '’',\n",
       " 'm',\n",
       " 'taking',\n",
       " 'this',\n",
       " 'book',\n",
       " 'with',\n",
       " 'me',\n",
       " 'wherever',\n",
       " 'I',\n",
       " 'go',\n",
       " 'and',\n",
       " 'using',\n",
       " 'it',\n",
       " 'to',\n",
       " 'discover',\n",
       " 'hidden',\n",
       " 'gem',\n",
       " ',',\n",
       " 'this',\n",
       " 'product',\n",
       " 'was',\n",
       " 'not',\n",
       " 'good',\n",
       " ',',\n",
       " 'i',\n",
       " 'love',\n",
       " 'this',\n",
       " 'product',\n",
       " ',',\n",
       " 'this',\n",
       " 'product',\n",
       " 'was',\n",
       " 'not',\n",
       " 'as',\n",
       " 'expected',\n",
       " ',',\n",
       " 'i',\n",
       " 'like',\n",
       " 'this',\n",
       " 'product',\n",
       " 'was',\n",
       " 'nice',\n",
       " 'to',\n",
       " 'use']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "token_sentences = sent_tokenize(text)\n",
    "token_sentences\n",
    "token_words = word_tokenize(text)\n",
    "token_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arabic', 'azerbaijani', 'basque', 'bengali', 'catalan', 'chinese', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hebrew', 'hinglish', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian', 'slovene', 'spanish', 'swedish', 'tajik', 'turkish']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.fileids())\n",
    "mystopwords = set(stopwords.words('english'))\n",
    "mystopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the new words without the common words is: ['best', ',', 'good', ',', 'better', ',', 'nice', ',', 'connectivity', ',', 'connection', ',', 'connecting', 'wanted', 'find', 'really', 'cool', 'new', 'places', 'Seattle', 'November', '.', '’', 'never', 'visited', 'luck', '.', 'suggestions', 'terrible', '...', 'laugh', '!', 'suggestions', 'typical', 'big', 'cities', ',', 'restaurants', 'bars', '.', 'Nothing', 'beaten', 'path', '.', '’', 'want', 'go', 'places', 'fun', '.', 'Totally', 'worth', 'getting', ',', 'beautiful', 'book', '.', '’', 'even', 'planning', 'travel', 'came', 'across', 'started', 'flipping', 'pages', '.', 'really', 'like', 'cover', 'large', 'glossy', 'photographs', 'book', '.', 'John', 'Smith', 'wonderful', 'job', 'photography', '.', '’', 'found', 'perfect', 'home', 'coffee', 'table', '.', '’', 'planning', 'trip', 'Paris', 'Barcelona', 'soon', 'know', 'come', 'handy', '.', 'meantime', ',', '’', 'perfect', 'assisting', 'armchair', 'traveler', ',', 'traveler', ',', 'really', 'appreciated', 'reading', 'great', 'places', 'visit', '.', 'author', 'takes', 'world', '.', 'Even', 'free', 'information', 'online', 'days', ',', 'find', '’', 'taking', 'book', 'wherever', 'go', 'using', 'discover', 'hidden', 'gem', ',', 'product', 'good', ',', 'love', 'product', ',', 'product', 'expected', ',', 'like', 'product', 'nice', 'use']\n"
     ]
    }
   ],
   "source": [
    "filtered_words =[]\n",
    "for word in token_words:\n",
    "    if word.lower() not in mystopwords:\n",
    "        filtered_words.append(word)\n",
    "print(\"the new words without the common words is:\",filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best',\n",
       " 'good',\n",
       " 'better',\n",
       " 'nice',\n",
       " 'connectivity',\n",
       " 'connection',\n",
       " 'connecting',\n",
       " 'wanted',\n",
       " 'find',\n",
       " 'really',\n",
       " 'cool',\n",
       " 'new',\n",
       " 'places',\n",
       " 'Seattle',\n",
       " 'November',\n",
       " 'never',\n",
       " 'visited',\n",
       " 'luck',\n",
       " 'suggestions',\n",
       " 'terrible',\n",
       " 'laugh',\n",
       " 'suggestions',\n",
       " 'typical',\n",
       " 'big',\n",
       " 'cities',\n",
       " 'restaurants',\n",
       " 'bars',\n",
       " 'Nothing',\n",
       " 'beaten',\n",
       " 'path',\n",
       " 'want',\n",
       " 'go',\n",
       " 'places',\n",
       " 'fun',\n",
       " 'Totally',\n",
       " 'worth',\n",
       " 'getting',\n",
       " 'beautiful',\n",
       " 'book',\n",
       " 'even',\n",
       " 'planning',\n",
       " 'travel',\n",
       " 'came',\n",
       " 'across',\n",
       " 'started',\n",
       " 'flipping',\n",
       " 'pages',\n",
       " 'really',\n",
       " 'like',\n",
       " 'cover',\n",
       " 'large',\n",
       " 'glossy',\n",
       " 'photographs',\n",
       " 'book',\n",
       " 'John',\n",
       " 'Smith',\n",
       " 'wonderful',\n",
       " 'job',\n",
       " 'photography',\n",
       " 'found',\n",
       " 'perfect',\n",
       " 'home',\n",
       " 'coffee',\n",
       " 'table',\n",
       " 'planning',\n",
       " 'trip',\n",
       " 'Paris',\n",
       " 'Barcelona',\n",
       " 'soon',\n",
       " 'know',\n",
       " 'come',\n",
       " 'handy',\n",
       " 'meantime',\n",
       " 'perfect',\n",
       " 'assisting',\n",
       " 'armchair',\n",
       " 'traveler',\n",
       " 'traveler',\n",
       " 'really',\n",
       " 'appreciated',\n",
       " 'reading',\n",
       " 'great',\n",
       " 'places',\n",
       " 'visit',\n",
       " 'author',\n",
       " 'takes',\n",
       " 'world',\n",
       " 'Even',\n",
       " 'free',\n",
       " 'information',\n",
       " 'online',\n",
       " 'days',\n",
       " 'find',\n",
       " 'taking',\n",
       " 'book',\n",
       " 'wherever',\n",
       " 'go',\n",
       " 'using',\n",
       " 'discover',\n",
       " 'hidden',\n",
       " 'gem',\n",
       " 'product',\n",
       " 'good',\n",
       " 'love',\n",
       " 'product',\n",
       " 'product',\n",
       " 'expected',\n",
       " 'like',\n",
       " 'product',\n",
       " 'nice',\n",
       " 'use']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_words = [word for word in filtered_words if word.isalpha()]\n",
    "clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('product', 4),\n",
       " ('really', 3),\n",
       " ('places', 3),\n",
       " ('book', 3),\n",
       " ('good', 2),\n",
       " ('nice', 2),\n",
       " ('find', 2),\n",
       " ('suggestions', 2),\n",
       " ('go', 2),\n",
       " ('planning', 2),\n",
       " ('like', 2),\n",
       " ('perfect', 2),\n",
       " ('traveler', 2),\n",
       " ('best', 1),\n",
       " ('better', 1),\n",
       " ('connectivity', 1),\n",
       " ('connection', 1),\n",
       " ('connecting', 1),\n",
       " ('wanted', 1),\n",
       " ('cool', 1),\n",
       " ('new', 1),\n",
       " ('Seattle', 1),\n",
       " ('November', 1),\n",
       " ('never', 1),\n",
       " ('visited', 1),\n",
       " ('luck', 1),\n",
       " ('terrible', 1),\n",
       " ('laugh', 1),\n",
       " ('typical', 1),\n",
       " ('big', 1)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "frequency = FreqDist(clean_words)\n",
    "frequency.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS  \n",
    "from PIL import Image\n",
    "\n",
    "def create_wordcloud(text):\n",
    "    stopwords = set(STOPWORDS) \n",
    "    font_path = \"Inktype-MAp2J.ttf\" \n",
    "    wc = WordCloud(background_color=\"white\", \n",
    "                   max_words=3000, \n",
    "                   stopwords=stopwords,\n",
    "                   font_path=\"Inktype-MAp2J.ttf\")  # Specify the font path\n",
    "    wc.generate(str(text)) \n",
    "    wc.to_file(\"wc.png\")\n",
    "    print(\"Word Cloud Saved Successfully\")\n",
    "    path=\"wc.png\" \n",
    "    display(Image.open(path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot open resource",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msup\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcreate_wordcloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[67], line 11\u001b[0m, in \u001b[0;36mcreate_wordcloud\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      6\u001b[0m font_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInktype-MAp2J.ttf\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m      7\u001b[0m wc \u001b[38;5;241m=\u001b[39m WordCloud(background_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhite\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      8\u001b[0m                max_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3000\u001b[39m, \n\u001b[1;32m      9\u001b[0m                stopwords\u001b[38;5;241m=\u001b[39mstopwords,\n\u001b[1;32m     10\u001b[0m                font_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInktype-MAp2J.ttf\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Specify the font path\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mwc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     12\u001b[0m wc\u001b[38;5;241m.\u001b[39mto_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwc.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWord Cloud Saved Successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:642\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m    628\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \n\u001b[1;32m    630\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 642\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:624\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \n\u001b[1;32m    609\u001b[0m \u001b[38;5;124;03mThe input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;124;03mself\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    623\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_text(text)\n\u001b[0;32m--> 624\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_frequencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:506\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# try to find a position\u001b[39;00m\n\u001b[0;32m--> 506\u001b[0m font \u001b[38;5;241m=\u001b[39m \u001b[43mImageFont\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtruetype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfont_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfont_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# transpose font optionally\u001b[39;00m\n\u001b[1;32m    508\u001b[0m transposed_font \u001b[38;5;241m=\u001b[39m ImageFont\u001b[38;5;241m.\u001b[39mTransposedFont(\n\u001b[1;32m    509\u001b[0m     font, orientation\u001b[38;5;241m=\u001b[39morientation)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/ImageFont.py:861\u001b[0m, in \u001b[0;36mtruetype\u001b[0;34m(font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m FreeTypeFont(font, size, index, encoding, layout_engine)\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfreetype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfont\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isPath(font):\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/ImageFont.py:858\u001b[0m, in \u001b[0;36mtruetype.<locals>.freetype\u001b[0;34m(font)\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfreetype\u001b[39m(font):\n\u001b[0;32m--> 858\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFreeTypeFont\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfont\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayout_engine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/ImageFont.py:203\u001b[0m, in \u001b[0;36mFreeTypeFont.__init__\u001b[0;34m(self, font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 load_from_bytes(f)\n\u001b[1;32m    202\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfont \u001b[38;5;241m=\u001b[39m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetfont\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfont\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayout_engine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayout_engine\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     load_from_bytes(font)\n",
      "\u001b[0;31mOSError\u001b[0m: cannot open resource"
     ]
    }
   ],
   "source": [
    "text = 'sup'\n",
    "create_wordcloud(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
